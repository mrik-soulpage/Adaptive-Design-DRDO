{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df461b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression as Lin_R\n",
    "import dask.dataframe as dd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ea1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EI(x0, max_mean_y):\n",
    "    \n",
    "    mean_y_new, sigma_y_new = x0\n",
    "    z = (mean_y_new - max_mean_y) / sigma_y_new\n",
    "    exp_imp = (mean_y_new - max_mean_y) * norm.cdf(z) + sigma_y_new * norm.pdf(z)\n",
    "    \n",
    "    return exp_imp\n",
    "\n",
    "\n",
    "\n",
    "def prediction_interval(inputs):\n",
    "    model, X_train, y_train, X = inputs\n",
    "    \n",
    "    # Number of training samples\n",
    "    n = X_train.shape[0]\n",
    "    nbootstraps = 1000    \n",
    "    bootstrap_preds = np.empty((X.shape[0],nbootstraps))\n",
    "    \n",
    "    #print('\\nBootstrapping..')\n",
    "    for b in tqdm(range(nbootstraps)):\n",
    "        train_idxs = np.random.choice(range(n), size = n, replace = True)\n",
    "        model.fit(X_train[train_idxs, :], y_train[train_idxs])\n",
    "        bootstrap_preds[:,b] = model.predict(X)\n",
    "    \n",
    "    ddf = dd.from_array(bootstrap_preds)\n",
    "    del bootstrap_preds\n",
    "    mean = ddf.mean(axis=1)\n",
    "    sd = ddf.std(axis=1)    \n",
    "    return mean, sd\n",
    "\n",
    "\n",
    "    \n",
    "def get_best_alloy_EI(df_test,max_mean_y):\n",
    "    \n",
    "    dd_test = dd.from_pandas(df_test[['Tmean','Tsd']], npartitions=30)\n",
    "    df_test['EI'] = dd_test.map_partitions(lambda df:df.apply((lambda x:EI(x,max_mean_y)),axis=1)).compute(scheduler='processes')\n",
    "\n",
    "    df_test.sort_values(ascending=False,inplace=True,by=['EI'])\n",
    "    \n",
    "    return df_test.index[0], df_test['Tpred'].loc[df_test.index[0]]\n",
    "\n",
    "\n",
    "\n",
    "def model_fit(df, df_test):\n",
    "    X = df.drop(['Tp'], axis=1)\n",
    "    y = df['Tp']\n",
    "    searchspace = df_test[['en','ven','dor']]\n",
    "    searchspace['dor2'] =  searchspace['dor'] ** 2\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_searchspace = scaler.transform(searchspace)\n",
    "    \n",
    "    model = Lin_R(fit_intercept = True, n_jobs = -1)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    y_pred = model.predict(X_searchspace)\n",
    "    max_mean_y = np.max(y)\n",
    "    \n",
    "    return X, y, model, X_searchspace, y_pred, max_mean_y\n",
    "\n",
    "\n",
    "    \n",
    "def train_loop(df ,df_test):\n",
    "    X, y, model, X_searchspace, y_pred, max_mean_y = model_fit(df, df_test)\n",
    "    mean, sd = prediction_interval([model, X, y, X_searchspace])\n",
    "    \n",
    "    mean = mean.compute().values\n",
    "    sd = sd.compute().values\n",
    "    \n",
    "    del df, X, X_searchspace\n",
    "    df_test['Tpred'] = y_pred\n",
    "    df_test['Tmean'] = mean\n",
    "    df_test['Tsd'] = sd\n",
    "    \n",
    "    best_alloy_index, t_pred = get_best_alloy_EI(df_test, max_mean_y)\n",
    "    return best_alloy_index, t_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0a0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##if __name__ == \"__main__\":\n",
    "#\n",
    "#def main_function(df, df_test):\n",
    "#    #df = pd.read_csv('training_data.csv', usecols=['en','ven','dor','Tp']) \n",
    "#    #df_test = pd.read_csv('search_space_2.csv')\n",
    "#    df['dor2'] = df['dor'] ** 2\n",
    "#    \n",
    "#    best_alloy_index, optimal_temp = train_loop(df.copy(), df_test.copy())\n",
    "#    \n",
    "#    #get the best alloy composition.\n",
    "#    df_test['predicted_target_variable'] = np.round(optimal_temp, 2)\n",
    "#    optimal_alloy = df_test.iloc[best_alloy_index]\n",
    "#    \n",
    "#    return optimal_alloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97e4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv('training_data.csv', usecols=['en','ven','dor','Tp']) \n",
    "#test_df = pd.read_csv('search_space_2.csv')\n",
    "#\n",
    "#output = main_function(train_df, test_df)\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9180bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [03:06<00:00,  5.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdor2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \n\u001b[0;32m      5\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_space_2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m best_alloy_index \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#get the best alloy composition.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_target_variable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(optimal_temp, \u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     72\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTmean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mean\n\u001b[0;32m     73\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTsd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sd\n\u001b[1;32m---> 75\u001b[0m best_alloy_index, t_pred \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_alloy_EI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_mean_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_alloy_index, t_pred\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mget_best_alloy_EI\u001b[1;34m(df_test, max_mean_y)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_alloy_EI\u001b[39m(df_test,max_mean_y):\n\u001b[0;32m     35\u001b[0m     dd_test \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mfrom_pandas(df_test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTsd\u001b[39m\u001b[38;5;124m'\u001b[39m]], npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEI\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdd_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m:\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mEI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_mean_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocesses\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     df_test\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEI\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_test\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m], df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTpred\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[df_test\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\base.py:290\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\base.py:573\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[0;32m    571\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 573\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\multiprocessing.py:220\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Note former versions used a multiprocessing Manager to share\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# a Queue between parent and workers, but this is fragile on Windows\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# (issue #1652).\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m    221\u001b[0m         pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m    222\u001b[0m         pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m    223\u001b[0m         dsk3,\n\u001b[0;32m    224\u001b[0m         keys,\n\u001b[0;32m    225\u001b[0m         get_id\u001b[38;5;241m=\u001b[39m_process_get_id,\n\u001b[0;32m    226\u001b[0m         dumps\u001b[38;5;241m=\u001b[39mdumps,\n\u001b[0;32m    227\u001b[0m         loads\u001b[38;5;241m=\u001b[39mloads,\n\u001b[0;32m    228\u001b[0m         pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m    229\u001b[0m         raise_exception\u001b[38;5;241m=\u001b[39mreraise,\n\u001b[0;32m    230\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    232\u001b[0m     )\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\local.py:495\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    494\u001b[0m     fire_tasks(chunksize)\n\u001b[1;32m--> 495\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m    497\u001b[0m             exc, tb \u001b[38;5;241m=\u001b[39m loads(res_info)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\local.py:126\u001b[0m, in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Empty:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "df = pd.read_csv('training_data.csv',usecols=['en','ven','dor','Tp'])\n",
    "df['dor2'] = df['dor'] ** 2 \n",
    "\n",
    "df_test = pd.read_csv('search_space_2.csv')\n",
    "\n",
    "best_alloy_index = train_loop(df.copy(),df_test.copy())\n",
    "#get the best alloy composition.\n",
    "df_test['predicted_target_variable'] = np.round(optimal_temp, 2)\n",
    "optimal_alloy = df_test.iloc[best_alloy_index]\n",
    "print(optimal_alloy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
